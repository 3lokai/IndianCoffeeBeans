# â˜• Indian Coffee Beans Scraper

A robust, scalable web scraper for extracting and enriching Indian coffee roaster product data. The system crawls coffee roaster websites to discover products, extract detailed information, and store it in a structured format for use in the IndianCoffeeBeans.com website.

## ğŸ“‹ Features

- **Multi-platform support:** Works with Shopify, WooCommerce, and custom websites
- **Intelligent discovery:** Uses multiple strategies to find products including API endpoints, sitemaps, structured data, and HTML crawling
- **Structured extraction:** Extracts detailed product attributes using JSON-CSS selectors
- **AI-powered enrichment:** Falls back to DeepSeek LLM for missing attributes
- **Database integration:** Direct upload to Supabase
- **Export options:** CSV and JSON export capabilities
- **Caching:** Smart caching system to minimize network requests
- **Scalable:** Configurable concurrency and batch processing

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9+
- Supabase account (optional)
- DeepSeek API key (optional, for AI enrichment)

### Installation

1. Clone the repository:

```bash
git clone https://github.com/yourusername/indian-coffee-beans-scraper.git
cd indian-coffee-beans-scraper
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Set up environment variables by creating a `.env` file:

```
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
DEEPSEEK_API_KEY=your_deepseek_api_key
```

4. Run the setup script to initialize the project:

```bash
python -m tests.test_setup
```

### Basic Usage

Run the scraper with a CSV file containing roaster information:

```bash
python main.py --input=data/roasters.csv
```

### Advanced Usage

```bash
# Force cache refresh
python main.py --input=data/roasters.csv --refresh

# Export results as CSV
python main.py --input=data/roasters.csv --export=coffees.csv

# Export as JSON 
python main.py --input=data/roasters.csv --export=coffees.json --format=json

# Skip database upload
python main.py --input=data/roasters.csv --no-db

# Process a single roaster
python main.py --input=data/roasters.csv --roaster="Blue Tokai Coffee Roasters"

# Control concurrency
python main.py --input=data/roasters.csv --concurrency=5

# Enable debug logging
python main.py --input=data/roasters.csv --debug
```

## ğŸ—‚ï¸ Project Structure

```
indian_coffee_beans_scraper/
â”œâ”€â”€ main.py                     # CLI runner
â”œâ”€â”€ config.py                   # Configuration 
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ requirements.txt            # Dependencies

â”œâ”€â”€ schemas/                    # JSON-CSS schemas
â”‚   â”œâ”€â”€ roaster_schema.py
â”‚   â””â”€â”€ product_schemas.py

â”œâ”€â”€ scrapers/                   # Core scraping components
â”‚   â”œâ”€â”€ pipeline.py             # Main pipeline orchestrator
â”‚   â”œâ”€â”€ roaster_pipeline.py     # Roaster metadata extraction
â”‚   â”œâ”€â”€ platform_detector.py    # Website platform detection
â”‚   â”œâ”€â”€ extractors/             # Product attribute extraction
â”‚   â”‚   â”œâ”€â”€ json_css_extractor.py
â”‚   â”‚   â””â”€â”€ deepseek_extractor.py
â”‚   â””â”€â”€ discoverers/            # Product URL discovery
â”‚       â”œâ”€â”€ discovery_manager.py
â”‚       â”œâ”€â”€ sitemap_discoverer.py
â”‚       â”œâ”€â”€ html_discoverer.py
â”‚       â””â”€â”€ structured_data_discoverer.py

â”œâ”€â”€ common/                     # Shared utilities
â”‚   â”œâ”€â”€ models.py               # Pydantic models
â”‚   â”œâ”€â”€ utils.py                # Helper functions
â”‚   â””â”€â”€ cache.py                # Caching system

â”œâ”€â”€ db/                         # Database integration
â”‚   â””â”€â”€ supabase_client.py      # Supabase client

â””â”€â”€ data/                       # Data files
    â”œâ”€â”€ cache/                  # Cache storage
    â””â”€â”€ output/                 # Export outputs
```

## ğŸ§ª Testing

Run tests to verify the functionality:

```bash
# Run all tests
python -m tests.run_tests

# Run specific tests
python -m tests.test_real_discoverers
python -m tests.test_real_extractors
```

## ğŸ“Š Database Schema

The system saves data according to the schema defined in `db_structure.md`.

### Main Tables

- `roasters`: Coffee roaster information
- `coffees`: Core coffee product details
- `coffee_prices`: Price points for different sizes
- `flavor_profiles`: Flavor characteristics
- `brew_methods`: Recommended brewing methods

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.